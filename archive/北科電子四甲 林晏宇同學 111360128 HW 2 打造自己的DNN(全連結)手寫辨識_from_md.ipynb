{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 【Demo01】設計你的神經網路\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[Image omitted]\n",
        "\n",
        "\n",
        "我們終於要開始做生命中第一個神經網路。要做的是 3 層深度學習, 因此請自行設第一層 N1 神經元, 第二層 N2, 第三層 N3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "N1 = 20\n",
        "N2 = 20\n",
        "N3 = 20\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 讀入套件\n",
        "\n",
        "這裡我們讀入一些套件, 今天暫時不要理會細節。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: pip\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# 標準數據分析、畫圖套件\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# 神經網路方面\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# 互動設計用\n",
        "from ipywidgets import interact_manual\n",
        "\n",
        "# 神速打造 web app 的 Gradio\n",
        "import gradio as gr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 讀入 MNIST 數據庫\n",
        "\n",
        "[Image omitted]\n",
        "\n",
        "MNIST 是有一堆 0-9 的手寫數字圖庫。有 6 萬筆訓練資料, 1 萬筆測試資料。它是 \"Modified\" 版的 NIST 數據庫, 原來的版本有更多資料。這個 Modified 的版本是由 LeCun, Cortes, 及 Burges 等人做的。可以參考這個數據庫的[原始網頁](http://yann.lecun.com/exdb/mnist/)。\n",
        "\n",
        "MNIST 可以說是 Deep Learning 最有名的範例, 它被 Deep Learning 大師 Hinton 稱為「機器學習的果蠅」。\n",
        "\n",
        "\n",
        "### 2.1 由 Keras 讀入 MNIST\n",
        "\n",
        "\n",
        "Keras 很貼心的幫我們準備好 MNIST 數據庫, 我們可以這樣讀進來 (第一次要花點時間)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我們來看看訓練資料是不是 6 萬筆、測試資料是不是有 1 筆。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "訓練資料總筆數為 60000 筆資料\n",
            "測試資料總筆數為 10000 筆資料\n"
          ]
        }
      ],
      "source": [
        "print(f'訓練資料總筆數為 {len(x_train)} 筆資料')\n",
        "print(f'測試資料總筆數為 {len(x_test)} 筆資料')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 數據庫的內容\n",
        "\n",
        "每筆輸入 (x) 就是一個手寫的 0-9 中一個數字的圖檔, 大小為 28x28。而輸出 (y) 當然就是「正確答案」。我們來看看編訓練資料的 x 輸入、輸出的部份分別長什麼樣子。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_xy(n=0):\n",
        "    ax = plt.gca()\n",
        "    X = x_train[n]\n",
        "    plt.xticks([], [])\n",
        "    plt.yticks([], [])\n",
        "    plt.imshow(X, cmap = 'Greys')\n",
        "    print(f'本資料 y 給定的答案為: {y_train[n]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09e615b14cea45b684476c2803550639",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='n', max=59999), Button(description='Run Interact', style…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "interact_manual(show_xy, n=(0,59999));\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_data(n = 100):\n",
        "    X = x_train[n]\n",
        "    print(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "266c4a157fa540fdb07ffbf516380de4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=100, description='n', max=59999), Button(description='Run Interact', sty…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "interact_manual(show_data, n=(0,59999));\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 輸入格式整理\n",
        "\n",
        "我們現在要用標準神經網路學學手寫辨識。原來的每筆數據是個 28x28 的矩陣 (array), 但標準神經網路只吃「平平的」, 也就是每次要 28x28=784 長的向量。因此我們要用 `reshape` 調校一下。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(60000, 784)/255\n",
        "x_test = x_test.reshape(10000, 784)/255\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 輸出格式整理\n",
        "[Image omitted]\n",
        "\n",
        "我們可能會想, 我們想學的函數是這樣的型式:\n",
        "\n",
        "$$\\hat{f} \\colon \\mathbb{R}^{784} \\to \\mathbb{R}$$\n",
        "\n",
        "其實這樣不太好! 為什麼呢? 比如說我們的輸入 x 是一張 0 的圖, 因為我們訓練的神經網路總會有點誤差, 所以可能會得到:\n",
        "\n",
        "$$\\hat{f}(x) = 0.5$$\n",
        "\n",
        "那這意思是有可能是 0, 也有可能是 1 嗎!!?? 可是 0 和 1 根本不像啊。換句話說分類的問題這樣做其實不合理!\n",
        "\n",
        "於是我們會做 \"1-hot enconding\", 也就是\n",
        "\n",
        "* 1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "* 5 -> [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
        "\n",
        "等等。因為分類問題基本上都要做這件事, Keras 其實已幫我們準備好套件!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我們來看看剛剛某號數據的答案。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = 87\n",
        "y_train[n]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "和我們想的一樣! 至此我們可以打造我們的神經網路了。\n",
        "\n",
        "\n",
        "## 3. 打造第一個神經網路\n",
        "\n",
        "我們決定了我們的函數是\n",
        "\n",
        "$$\\hat{f} \\colon \\mathbb{R}^{784} \\to \\mathbb{R}^{10}$$\n",
        "\n",
        "這個樣子。而我們又說第一次要用標準神網路試試, 所以我們只需要再決定要幾個隱藏層、每層要幾個神經元, 用哪個激發函數就可以了。\n",
        "\n",
        "\n",
        "### 3.1 決定神經網路架構、讀入相關套件\n",
        "\n",
        "假如我們要用 ReLU 當激發函數, 要設計神經網路, 只差要指定多少個隱藏層、每層多少個神經元就好了!\n",
        "\n",
        "設計完了基本上就是告訴 TensorFlow, 我們的想法就可以了!\n",
        "\n",
        "\n",
        "### 3.2 建構我們的神經網路\n",
        "\n",
        "和以前做迴歸或機器學習一樣, 我們就打開個「函數學習機」。標準一層一層傳遞的神經網路叫 `Sequential`, 於是我們打開一個空的神經網路。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我們每次用 `add` 去加一層, 從第一個隱藏層開始。而第一個隱藏層因為 TensorFlow 當然猜不到輸入有 784 個 features, 所以我們要告訴它。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.add(Dense(N1, input_dim=784, activation='relu'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "第二層開始就不用再說明輸入神經元個數 (因為就是前一層神經元數)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.add(Dense(N2, activation='relu'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.add(Dense(N3, activation='relu'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "輸出有 10 個數字, 所以輸出層的神經元是 10 個! 而如果我們的網路輸出是\n",
        "\n",
        "$$(y_1, y_2, \\ldots, y_{10})$$\n",
        "\n",
        "我們還希望\n",
        "\n",
        "$$\\sum_{i=1}^{10} y_i = 1$$\n",
        "\n",
        "這可能嗎, 結果是很容易, 就用 `softmax` 當激發函數就可以!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.add(Dense(10, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "至此我們的第一個神經網路就建好了!\n",
        "\n",
        "\n",
        "### 3.3 組裝\n",
        "\n",
        "和之前比較不一樣的是我們還要做 `compile` 才正式把我們的神經網路建好。你可以發現我們還需要做幾件事:\n",
        "\n",
        "* 決定使用的 loss function, 一般是 `mse`\n",
        "* 決定 optimizer, 我們用標準的 SGD\n",
        "* 設 learning rate\n",
        "\n",
        "為了一邊訓練一邊看到結果, 我們加設\n",
        "\n",
        "    metrics=['accuracy']\n",
        "    \n",
        "本行基本上和我們的神經網路功能沒有什麼關係。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss='mse', optimizer=SGD(learning_rate=0.087), metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 檢視我們的神經網路\n",
        "\n",
        "\n",
        "我們可以檢視我們神經網路的架構, 可以確認一下是不是和我們想像的一樣。\n",
        "\n",
        "\n",
        "### 4.1 看 model 的 summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "很快算算參數數目和我們想像是否是一樣的!\n",
        "\n",
        "\n",
        "## 5. 訓練你的第一個神經網路\n",
        "\n",
        "恭喜! 我們完成了第一個神經網路。現在要訓練的時候, 你會發現不是像以前沒頭沒腦把訓練資料送進去就好。這裡我們還有兩件事要決定:\n",
        "\n",
        "* 一次要訓練幾筆資料 (`batch_size`), 我們就 100 筆調一次參數好了\n",
        "* 這 6 萬筆資料一共要訓練幾次 (`epochs`), 我們訓練個 10 次試試\n",
        "\n",
        "於是最精彩的就來了。你要有等待的心理準備..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train, batch_size=100, epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 試用我們的結果\n",
        "\n",
        "我們來用比較炫的方式來看看可愛的神經網路學習成果。對指令有問題可以參考《少年Py的大冒險：成為Python數據分析達人的第一門課》。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"測試資料正確率 {acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我們 \"predict\" 放的是我們神經網路的學習結果。做完之後用 argmax 找到數值最大的那一項。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predict = np.argmax(model.predict(x_test), axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "不要忘了我們的 `x_test` 每筆資料已經換成 784 維的向量, 我們要整型回 28x28 的矩陣才能當成圖形顯示出來!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(測試編號):\n",
        "    plt.imshow(x_test[測試編號].reshape(28,28), cmap='Greys')\n",
        "    print('神經網路判斷為:', predict[測試編號])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "interact_manual(test, 測試編號=(0, 9999));\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "到底測試資料總的狀況如何呢? 我們可以給我們神經網路「總評量」。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "score = model.evaluate(x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('loss:', score[0])\n",
        "print('正確率', score[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. 用 Gradio 來展示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resize_image(inp):\n",
        "    # 圖在 inp[\"layers\"][0]\n",
        "    image = np.array(inp[\"layers\"][0], dtype=np.float32)\n",
        "    image = image.astype(np.uint8)\n",
        "\n",
        "    # 轉成 PIL 格式\n",
        "    image_pil = Image.fromarray(image)\n",
        "\n",
        "    # Alpha 通道設為白色, 再把圖從 RGBA 轉成 RGB\n",
        "    background = Image.new(\"RGB\", image_pil.size, (255, 255, 255))\n",
        "    background.paste(image_pil, mask=image_pil.split()[3]) # 把圖片粘貼到白色背景上，使用透明通道作為遮罩\n",
        "    image_pil = background\n",
        "\n",
        "    # 轉換為灰階圖像\n",
        "    image_gray = image_pil.convert(\"L\")\n",
        "\n",
        "    # 將灰階圖像縮放到 28x28, 轉回 numpy array\n",
        "    img_array = np.array(image_gray.resize((28, 28), resample=Image.LANCZOS))\n",
        "\n",
        "    # 配合 MNIST 數據集\n",
        "    img_array = 255 - img_array\n",
        "\n",
        "    # 拉平並縮放\n",
        "    img_array = img_array.reshape(1, 784) / 255.0\n",
        "\n",
        "    return img_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recognize_digit(inp):\n",
        "    img_array = resize_image(inp)\n",
        "    prediction = model.predict(img_array).flatten()\n",
        "    labels = list('0123456789')\n",
        "    return {labels[i]: float(prediction[i]) for i in range(10)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iface = gr.Interface(\n",
        "    fn=recognize_digit,\n",
        "    inputs=gr.Sketchpad(),\n",
        "    outputs=gr.Label(num_top_classes=3),\n",
        "    title=\"MNIST 手寫辨識\",\n",
        "    description=\"請在畫板上繪製數字\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True, debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
